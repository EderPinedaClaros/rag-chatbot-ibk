{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Documento Modelo Comportamental BPE 1.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1117, which is longer than the specified 1000\n",
      "Created a chunk of size 1117, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/DocumentoAdmisionBankQuickWin_comentariosAIS_respuesta_v6 (2).docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1117, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MODELO ORIGEN NO BANK BPE v9 1 (1).docx\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "list_docs = [\"data/Documento Modelo Comportamental BPE 1.docx\", \"data/DocumentoAdmisionBankQuickWin_comentariosAIS_respuesta_v6 (2).docx\", \"data/MODELO ORIGEN NO BANK BPE v9 1 (1).docx\"]\n",
    "\n",
    "list_nmodels = {\n",
    "    \"data/Documento Modelo Comportamental BPE 1.docx\" : \"bpe\",\n",
    "    \"data/DocumentoAdmisionBankQuickWin_comentariosAIS_respuesta_v6 (2).docx\" : \"quickwin\",\n",
    "    \"data/MODELO ORIGEN NO BANK BPE v9 1 (1).docx\" : \"nobankbpe\"\n",
    "}\n",
    "\n",
    "for word in list_docs:\n",
    "    print(word)\n",
    "\n",
    "    loader = Docx2txtLoader(word)\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator = \"\\n\\n\",\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False\n",
    "    )\n",
    "\n",
    "    docs = text_splitter.split_documents(data)\n",
    "\n",
    "    vs = FAISS.from_documents(docs, embeddings)\n",
    "    vs.save_local(\"data\" + list_nmodels[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Responda a la pregunta basada en el siguiente contexto.\n",
    "Si no puedes responder a la pregunta, usa la siguiente respuesta \"No lo sé disculpa.\"\n",
    "\n",
    "Contexto: \n",
    "{context}\n",
    "Pregunta: {question}\n",
    "Respuesta: \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template, input_variables = [\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = 'gpt-3.5-turbo-0125', ##Es el modelo más barato dentro de la familia GPT3.5 Turbo\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm, \n",
    "    chain_type = \"stuff\", \n",
    "    retriever = vs.as_retriever(search_kwargs = {'k': 5 }), #Por defecto recupera los 4 documentos más relevantes as_retriever(search_kwargs={'k': 3 })\n",
    "    chain_type_kwargs = {\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El modelo Comportamental BPE es un modelo matemático que clasifica a un cliente según su perfil de riesgo en las categorías de bueno o malo, basado en la probabilidad de caer en default (incumplimiento) a través de la evaluación de variables que perfilan al cliente y la asignación de puntajes de riesgo.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"¿Que es el modelo Comportamental BPE?\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Las principales fuentes utilizadas son: \\n1. Base RCC (Base Sistema Financiera)\\n2. Base SUNAT (Base Proveedor)\\n3. Base ADEX (Base Proveedor)\\n4. Base DEMOGRAFICAS (Base interna)\\n5. Base SENTINEL (Base Proveedor)\\n6. Base ENRICH (Base Proveedor)\\n7. Base SUNARP (Base Proveedor)\\n8. Base IZIPAY (Base interna)\\n9. Base Cambio de Fecha – Cuotas (Bases internas de Interbank)\\n10. Base Reniec (Base comprada)\\n11. Base Pasivos (Base Interna)\\n12. Base Transacciones Empresa (Base Interna)\\n13. Base Proveedores (Base Interna)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"¿Cuales son principales fuentes utiizadas, puedes tabularlas?\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"¿Cual ha sido el periodo de observación para la construcción del modelo?\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"descripción de las variables del modelo\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"cuál es el performance del modelo\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"¿Cual ha sido el periodo de observación para la construcción del modelo?\")[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
